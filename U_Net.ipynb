{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Importação das Bibliotecas Necessárias**"
      ],
      "metadata": {
        "id": "blG8NolQvJoM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Sawj_sVysQW"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from tensorflow.keras import layers, models\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Google Drive**"
      ],
      "metadata": {
        "id": "XwHX3FGQvUxU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "SOYkPok-pN6J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Definir de Parametros e Imagens**"
      ],
      "metadata": {
        "id": "cJoPOlMZvdWH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define paths\n",
        "images_dir = '/content/drive/MyDrive/Modelos/dataset/images'\n",
        "masks_dir = '/content/drive/MyDrive/Modelos/dataset/masks'"
      ],
      "metadata": {
        "id": "i45ZBUIbbU4_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "img_height, img_width = 512, 512  # Desired dimensions\n",
        "batch_size = 8  # Adjust based on memory constraints"
      ],
      "metadata": {
        "id": "oe5kcFT3bWP4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Carregamento e Pré-processamento de imagens**"
      ],
      "metadata": {
        "id": "AKbxeEGFvoNc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to load and preprocess images and masks\n",
        "def load_and_preprocess_image(img_path, mask_path, target_size=(img_height, img_width)):\n",
        "    image = load_img(img_path, target_size=target_size)\n",
        "    image = img_to_array(image) / 255.0  # Normalize to [0, 1]\n",
        "\n",
        "    mask = load_img(mask_path, target_size=target_size, color_mode=\"grayscale\")\n",
        "    mask = img_to_array(mask) / 255.0  # Normalize to [0, 1]\n",
        "    mask = np.round(mask)  # Ensure mask is binary (0 or 1)\n",
        "\n",
        "    return image, mask"
      ],
      "metadata": {
        "id": "TljIeX4obU7c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get list of image and mask files\n",
        "image_files = sorted(os.listdir(images_dir))\n",
        "mask_files = sorted(os.listdir(masks_dir))"
      ],
      "metadata": {
        "id": "pomnMuqhbVAO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure the number of images and masks match\n",
        "assert len(image_files) == len(mask_files)"
      ],
      "metadata": {
        "id": "C4AAStKcbVCY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset into training and validation sets\n",
        "train_images, val_images, train_masks, val_masks = train_test_split(\n",
        "    image_files, mask_files, test_size=0.2, random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "1m3_k_DbbVE8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and preprocess all data\n",
        "train_images = [load_and_preprocess_image(os.path.join(images_dir, img), os.path.join(masks_dir, msk)) for img, msk in zip(train_images, train_masks)]\n",
        "val_images = [load_and_preprocess_image(os.path.join(images_dir, img), os.path.join(masks_dir, msk)) for img, msk in zip(val_images, val_masks)]"
      ],
      "metadata": {
        "id": "gjfPZmvCbhvL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate images and masks\n",
        "train_images, train_masks = zip(*train_images)\n",
        "val_images, val_masks = zip(*val_images)"
      ],
      "metadata": {
        "id": "ltdCOQJUbhxa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert lists to numpy arrays\n",
        "train_images = np.array(train_images)\n",
        "train_masks = np.array(train_masks)\n",
        "val_images = np.array(val_images)\n",
        "val_masks = np.array(val_masks)"
      ],
      "metadata": {
        "id": "udQTILAdbhz6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create TensorFlow datasets\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_masks)).batch(batch_size)\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_masks)).batch(batch_size)"
      ],
      "metadata": {
        "id": "zy4g3NJJbh2T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Construção do Modelo**"
      ],
      "metadata": {
        "id": "onq2GW24v0To"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define U-Net model\n",
        "def build_unet(input_shape):\n",
        "    inputs = tf.keras.Input(shape=input_shape)\n",
        "\n",
        " # Encoder\n",
        "    c1 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n",
        "    c1 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(c1)\n",
        "    p1 = layers.MaxPooling2D((2, 2))(c1)\n",
        "\n",
        "    c2 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(p1)\n",
        "    c2 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(c2)\n",
        "    p2 = layers.MaxPooling2D((2, 2))(c2)\n",
        "\n",
        "    c3 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(p2)\n",
        "    c3 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(c3)\n",
        "    p3 = layers.MaxPooling2D((2, 2))(c3)\n",
        "\n",
        "    c4 = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(p3)\n",
        "    c4 = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(c4)\n",
        "    p4 = layers.MaxPooling2D((2, 2))(c4)\n",
        "\n",
        "    # Bottleneck\n",
        "    c5 = layers.Conv2D(1024, (3, 3), activation='relu', padding='same')(p4)\n",
        "    c5 = layers.Conv2D(1024, (3, 3), activation='relu', padding='same')(c5)\n",
        "\n",
        "    # Decoder\n",
        "    u6 = layers.Conv2DTranspose(512, (2, 2), strides=(2, 2), padding='same')(c5)\n",
        "    u6 = layers.concatenate([u6, c4])\n",
        "    c6 = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(u6)\n",
        "    c6 = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(c6)\n",
        "\n",
        "    u7 = layers.Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(c6)\n",
        "    u7 = layers.concatenate([u7, c3])\n",
        "    c7 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(u7)\n",
        "    c7 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(c7)\n",
        "\n",
        "    u8 = layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c7)\n",
        "    u8 = layers.concatenate([u8, c2])\n",
        "    c8 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(u8)\n",
        "    c8 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(c8)\n",
        "\n",
        "    u9 = layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c8)\n",
        "    u9 = layers.concatenate([u9, c1])\n",
        "    c9 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(u9)\n",
        "    c9 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(c9)\n",
        "\n",
        "    outputs = layers.Conv2D(1, (1, 1), activation='sigmoid', padding='same')(c9)\n",
        "\n",
        "    model = models.Model(inputs, outputs)\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "60snyXhmbnZl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Treino**"
      ],
      "metadata": {
        "id": "gv0cZW8zwI6v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build U-Net model\n",
        "unet_model = build_unet((img_height, img_width, 3))\n",
        "\n",
        "unet_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "unet_history = unet_model.fit(train_dataset, epochs=30, validation_data=val_dataset)"
      ],
      "metadata": {
        "id": "PMqH3UBkbncE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Visualização**"
      ],
      "metadata": {
        "id": "cRvOIqmQxIkj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to plot training history\n",
        "def plot_history(history, title):\n",
        "    acc = history.history['accuracy']\n",
        "    val_acc = history.history['val_accuracy']\n",
        "    loss = history.history['loss']\n",
        "    val_loss = history.history['val_loss']\n",
        "    epochs = range(len(acc))\n",
        "\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "    plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "    plt.title(f'Training and Validation Accuracy: {title}')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(epochs, loss, 'r', label='Training loss')\n",
        "    plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "    plt.title(f'Training and Validation Loss: {title}')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "Gm3ExY2cbwjD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_history(unet_history, 'U-Net')"
      ],
      "metadata": {
        "id": "QJcacCiibwlp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Teste e Previão**"
      ],
      "metadata": {
        "id": "ebprrwQVxOEO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_iou(pred_mask, true_mask):\n",
        "    \"\"\"\n",
        "    Calculate the Intersection over Union (IoU) score between the predicted mask and the ground truth mask.\n",
        "\n",
        "    Parameters:\n",
        "    - pred_mask: numpy array of the predicted mask.\n",
        "    - true_mask: numpy array of the ground truth mask.\n",
        "\n",
        "    Returns:\n",
        "    - iou: IoU score.\n",
        "    \"\"\"\n",
        "    # Ensure masks are binary\n",
        "    pred_mask = np.round(pred_mask).astype(np.uint8)\n",
        "    true_mask = np.round(true_mask).astype(np.uint8)\n",
        "\n",
        "    # Calculate Intersection and Union\n",
        "    intersection = np.logical_and(pred_mask, true_mask).sum()\n",
        "    union = np.logical_or(pred_mask, true_mask).sum()\n",
        "\n",
        "    # Calculate IoU\n",
        "    if union == 0:\n",
        "        return 0.0  # Avoid division by zero\n",
        "    iou = intersection / union\n",
        "    return iou"
      ],
      "metadata": {
        "id": "Qfq74QyxcRH6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_and_display_mask(model, image_path, ground_truth_path, target_size=(img_height, img_width)):\n",
        "    \"\"\"\n",
        "    Predict and display the mask for an external image using the trained model and compare it with the ground truth mask.\n",
        "    Display the IoU score as well.\n",
        "\n",
        "    Parameters:\n",
        "    - model: Trained U-Net model.\n",
        "    - image_path: Path to the external image.\n",
        "    - ground_truth_path: Path to the ground truth mask.\n",
        "    - target_size: Tuple of target image size (height, width).\n",
        "    \"\"\"\n",
        "    # Load and preprocess the image\n",
        "    image = load_img(image_path, target_size=target_size)\n",
        "    image_array = img_to_array(image) / 255.0  # Normalize to [0, 1]\n",
        "    image_array = np.expand_dims(image_array, axis=0)  # Add batch dimension\n",
        "\n",
        "    # Predict the mask\n",
        "    predicted_mask = model.predict(image_array)[0]\n",
        "\n",
        "    # Post-process the mask (if necessary, e.g., thresholding)\n",
        "    predicted_mask = np.round(predicted_mask).astype(np.uint8).squeeze()  # Remove batch dimension\n",
        "\n",
        "    # Load and preprocess the ground truth mask\n",
        "    ground_truth_mask = load_img(ground_truth_path, target_size=target_size, color_mode=\"grayscale\")\n",
        "    ground_truth_mask = img_to_array(ground_truth_mask) / 255.0  # Normalize to [0, 1]\n",
        "    ground_truth_mask = np.round(ground_truth_mask).astype(np.uint8).squeeze()  # Ensure mask is binary (0 or 1) and remove single channel dimension\n",
        "\n",
        "    # Calculate IoU score\n",
        "    iou_score = calculate_iou(predicted_mask, ground_truth_mask)\n",
        "    print(f\"IoU Score: {iou_score:.4f}\")\n",
        "\n",
        "    # Display the image, the ground truth mask, and the predicted mask\n",
        "    plt.figure(figsize=(15, 5))\n",
        "\n",
        "    plt.subplot(1, 3, 1)\n",
        "    plt.imshow(image)\n",
        "    plt.title(\"Original Image\")\n",
        "\n",
        "    plt.subplot(1, 3, 2)\n",
        "    plt.imshow(predicted_mask, cmap='gray')\n",
        "    plt.title(\"Predicted Mask\")\n",
        "\n",
        "    plt.subplot(1, 3, 3)\n",
        "    plt.imshow(ground_truth_mask, cmap='gray')\n",
        "    plt.title(\"Ground Truth Mask\")\n",
        "\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "CQnzkKngbweN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict and display mask for an external image\n",
        "image_path = '/content/drive/MyDrive/Modelos/dataset/test_images/daea4860-a296-4f6d-acef-996ab0882676.png'\n",
        "ground_truth_path = '/content/drive/MyDrive/Modelos/dataset/test_masks/daea4860-a296-4f6d-acef-996ab0882676.png'\n",
        "predict_and_display_mask(unet_model, image_path, ground_truth_path)"
      ],
      "metadata": {
        "id": "_UHvQo_kbwne"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Guardar o Modelo Treinado**"
      ],
      "metadata": {
        "id": "XwvaDMeexUtd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to save the model\n",
        "def save_model(model, save_path):\n",
        "    \"\"\"\n",
        "    Save the trained model to the specified path.\n",
        "\n",
        "    Parameters:\n",
        "    - model: Trained Keras model.\n",
        "    - save_path: Path to save the model.\n",
        "    \"\"\"\n",
        "    model.save(save_path)\n",
        "    print(f\"Model saved to {save_path}\")\n"
      ],
      "metadata": {
        "id": "D__BceNZbngx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}